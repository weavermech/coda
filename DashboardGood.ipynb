{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020,2024 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Disease Tracking Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template for your DIY Disease Tracking Dashboard, to which you can add the code you developed in the previous notebooks. The dashboard will be displayed using [voila](https://voila.readthedocs.io/en/stable/index.html), a Python dashboarding tool that converts notebooks to standalone dashboards. Contrary to the other libraries we have seen, the ```voila``` package must be installed using *pip* or *conda* but it does not need to be imported - it rather acts at the level of the notebook server. Package ```voila``` is already installed on the QMUL JupyterHub as well as in the Binder - to install it locally, follow the [instructions](https://voila.readthedocs.io/en/stable/install.html) online.\n",
    "\n",
    "Broadly speaking, Voila acts by **running all the cells in your notebook** when the dashboard is first loaded; it then hides all code cells and displays all markdown cells and any outputs, including widgets. However, the code is still there in the background and handles any interaction with the widgets. To view this dashboard template rendered in Voila click [here](https://mybinder.org/v2/gh/fsmeraldi/diy-covid19dash/main?urlpath=%2Fvoila%2Frender%2FDashboard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "from anytree.importer import JsonImporter, DictImporter\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning) # , message=\"Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "global regions \n",
    "regions = [\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"]\n",
    "global filters\n",
    "filters={\"stratum\" : None, # Smallest subgroup a metric can be broken down into e.g. ethnicity, testing pillar\n",
    "    \"age\": None, # Smallest subgroup a metric can be broken down into e.g. 15_44 for the age group of 15-44 years\n",
    "    \"sex\": None, #  Patient gender e.g. 'm' for Male, 'f' for Female or 'all' for all genders\n",
    "    \"year\": None,#2022, #  Epi year of the metrics value (important for annual metrics) e.g. 2020\n",
    "    \"month\": None, # Epi month of the metric value (important for monthly metrics) e.g. 12\n",
    "    \"epiweek\" :None, # Epi week of the metric value (important for weekly metrics) e.g. 30\n",
    "    \"date\" : None, # The date which this metric value was recorded in the format YYYY-MM-DD e.g. 2020-07-20\n",
    "    \"in_reporting_delay_period\": None # Boolean indicating whether the data point is considered to be subject to retrospective updates\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial data from disk\n",
    "\n",
    "You should include \"canned\" data in ```.json``` files along with your dashboard. When the dashboard starts, it should load that data and assign it as a dictionary to the ```jsondata``` variable (the code below will be hidden when the dashboard is rendered by Voila)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "with open(\"mean_occBed_region.json\", \"rt\") as INFILE:\n",
    "    mean_occBed_region=json.load(INFILE)\n",
    "\n",
    "with open(\"leaf_first.json\", \"rt\") as INFILE:\n",
    "    leaf_data =json.load(INFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the data\n",
    "\n",
    "The dashboard should contain the logic to wrangle the raw data into a ```DataFrame``` (or more than one, as required) that will be used for plotting. The wrangling code should be put into a function and called on the data from the JSON file (we'll need to call it again on any data downloaded from the API).  In this template, we just pretend we are wrangling ```rawdata``` and instead generate a dataframe with some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 00:00:00  to  2024-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def wrangle_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    \n",
    "    def parse_date(datestring):\n",
    "        \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "        return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "    data={}\n",
    "    for dataset in rawdata:\n",
    "        for entry in dataset:\n",
    "            date=entry['date']\n",
    "            value=entry['metric_value']\n",
    "            geography=entry['geography']\n",
    "            if date not in data:\n",
    "                data[date]={}\n",
    "            data[date][geography]=value\n",
    "\n",
    "    dates=list(data.keys())\n",
    "    dates.sort()\n",
    "\n",
    "    startdate=parse_date(dates[0])\n",
    "    enddate=parse_date(dates[-1])\n",
    "    print (startdate, ' to ', enddate)\n",
    "\n",
    "    index=pd.date_range(startdate, enddate, freq='D')\n",
    "    mean_occBed_region_df=pd.DataFrame(index=index, columns=regions)\n",
    "\n",
    "\n",
    "    for date, values in data.items():\n",
    "        for region, value in values.items():\n",
    "            mean_occBed_region_df.at[parse_date(date), region] = value\n",
    "    # fill in any remaining \"holes\" due to missing dates\n",
    "    mean_occBed_region_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    return mean_occBed_region_df\n",
    "\n",
    "    \n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n",
    "df1=wrangle_data(mean_occBed_region) # df is the dataframe for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your users an option to refresh the dataset - a \"refresh\" button will do. The button callback should\n",
    "* call the code that accesses the API and download some fresh raw data;\n",
    "* wrangle that data into a dataframe and update the corresponding (global) variable for plotting (here, ```df```);\n",
    "* optionally: force a redraw of the graph and give the user some fredback.\n",
    "\n",
    "Once you get it to work, you may want to wrap your API call inside an exception handler, so that the user is informed, the \"canned\" data are not overwritten and nothing crashes if for any reason the server cannot be reached or data are not available.\n",
    "\n",
    "After you refresh the data, graphs will not update until the user interacts with a widget. You can trick ```iPywidgets``` into redrawing the graph by simulating interaction, as in the ```refresh_graph``` function we define in the Graph and Analysis section below.\n",
    "\n",
    "In this example, clicking on the button below just generates some more random data and refreshes the graph. The button should read *Fetch Data*. If you see anything else, take a deep breath :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the UKHSA API. Return data as a like-for-like replacement for the \"canned\" data loaded from the JSON file. \"\"\"\n",
    "    \n",
    "    class APIwrapper:\n",
    "        # class variables shared among all instances\n",
    "        _access_point=\"https://api.ukhsa-dashboard.data.gov.uk/v2\"       \n",
    "        _last_access=0.0 # time of last api access\n",
    "        root = Node(\"root\")\n",
    "        \n",
    "        def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "            \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "            parameters \"\"\"\n",
    "            # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "            # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "            url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                    f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "            # our starting API endpoint\n",
    "            self._start_url=APIwrapper._access_point+url_path\n",
    "            self._filters=None\n",
    "            self._page_size=-1\n",
    "            # will contain the number of items\n",
    "            self.count=None\n",
    "\n",
    "\n",
    "\n",
    "        def get_page(self, filters={}, page_size=5):\n",
    "            \"\"\" Access the API and download the next page of data. Sets the count\n",
    "            attribute to the total number of items available for this query. Changing\n",
    "            filters or page_size will cause get_page to restart from page 1. Rate\n",
    "            limited to three request per second. The page_size parameter sets the number\n",
    "            of data points in one response page (maximum 365); use the default value \n",
    "            for debugging your structure and filters. \"\"\"\n",
    "            # Check page size is within range\n",
    "            if page_size>365:\n",
    "                raise ValueError(\"Max supported page size is 365\")\n",
    "            # restart from first page if page or filters have changed\n",
    "            if filters!=self._filters or page_size!=self._page_size:\n",
    "                self._filters=filters\n",
    "                self._page_size=page_size\n",
    "                self._next_url=self._start_url\n",
    "            # signal the end of data condition\n",
    "            if self._next_url==None: \n",
    "                return [] # we already fetched the last page\n",
    "            # simple rate limiting to avoid bans\n",
    "            curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "            deltat=curr_time-APIwrapper._last_access\n",
    "            if deltat<0.33: # max 3 requests/second\n",
    "                time.sleep(0.33-deltat)\n",
    "            APIwrapper._last_access=curr_time\n",
    "            # build parameter dictionary by removing all the None\n",
    "            # values from filters and adding page_size\n",
    "            parameters={x: y for x, y in filters.items() if y!=None}\n",
    "            parameters['page_size']=page_size\n",
    "            # the page parameter is already included in _next_url.\n",
    "            # This is the API access. Response is a dictionary with various keys.\n",
    "            # the .json() method decodes the response into Python object (dictionaries,\n",
    "            # lists; 'null' values are translated as None).\n",
    "            response = requests.get(self._next_url, params=parameters).json()\n",
    "            # update url so we'll fetch the next page\n",
    "            self._next_url=response['next']\n",
    "            self.count=response['count']\n",
    "            # data are in the nested 'results' list\n",
    "            return response['results'] \n",
    "\n",
    "        def get_all_pages(self, filters={}, page_size=365):\n",
    "            \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "            attribute to the total number of items available for this query. API access rate\n",
    "            limited to three request per second. The page_size parameter sets the number\n",
    "            of data points in one response page (maximum 365), and controls the trade-off\n",
    "            between time to load a page and number of pages; the default should work well \n",
    "            in most cases. The number of items returned should in any case be equal to \n",
    "            the count attribute. \"\"\"\n",
    "            data=[] # build up all data here\n",
    "            while True:\n",
    "                # use get_page to do the job, including the pacing\n",
    "                next_page=self.get_page(filters, page_size)\n",
    "                if next_page==[]:\n",
    "                    break # we are done\n",
    "                data.extend(next_page)\n",
    "            return data\n",
    "\n",
    "\n",
    "        # /themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/{geography_type}/geographies/{geography}/metrics/{metric}\n",
    "        def add_branch_to_node(self, upper_node=None, link=None):\n",
    "        \n",
    "            # to kick off the tere from scratch\n",
    "            # had some problems with using defualt values in the function so dealing with it here\n",
    "            if upper_node is None:\n",
    "                upper_node = APIwrapper.root\n",
    "            if link is None:\n",
    "                link = APIwrapper._access_point + '/themes/'\n",
    "                \n",
    "            importer = DictImporter()\n",
    "            curr_time = time.time()  # Unix time: number of seconds since the Epoch\n",
    "            deltat = curr_time - APIwrapper._last_access\n",
    "            if deltat < 0.33:  # max 3 requests/second\n",
    "                time.sleep(0.33 - deltat)\n",
    "            APIwrapper._last_access = curr_time\n",
    "\n",
    "            branches = requests.get(link).json()\n",
    "            if branches:                                                # make this better api stuff, 200?\n",
    "                for branch in branches:\n",
    "                    new_node = importer.import_(branch)\n",
    "                    new_node.parent = upper_node\n",
    "                    new_node.name = branch['name']                      # Use the value of the \"name\" dictionary key\n",
    "\n",
    "                    curr_time = time.time()                             # Unix time: number of seconds since the Epoch\n",
    "                    deltat = curr_time - APIwrapper._last_access\n",
    "                    if deltat < 0.33:                                   # max 3 requests/second\n",
    "                        time.sleep(0.33 - deltat)\n",
    "                    APIwrapper._last_access = curr_time\n",
    "                    next_level_link = branch['link']                    # get the link to the next section in the api\n",
    "\n",
    "                    if \"/metrics/\" in next_level_link:                  # hacky way to get to find if we are at the bottom of the tree (metric data is next)\n",
    "                        continue                                        # continue to next branch\n",
    "\n",
    "                    options_link = requests.get(next_level_link).json() # get the link that returns the options for the next branch\n",
    "                    options_link = list(options_link[0].values())[0]\n",
    "                    \n",
    "\n",
    "\n",
    "                    self.add_branch_to_node(new_node, options_link)     # recursively add the next branch to the tree\n",
    "\n",
    "            return\n",
    "    \n",
    "    # This Builds The Tree !!It Takes Over 50min To Run on Local Machine!!\n",
    "    # api.add_branch_to_node()\n",
    "    \n",
    "    # Load the tree from a pickle file instead\n",
    "    global root\n",
    "    # root = api.root\n",
    "    with open('full_tree_named.pkl', 'rb') as f:\n",
    "        root = pickle.load(f)\n",
    "\n",
    "    structure={\"theme\": \"infectious_disease\", \n",
    "        \"sub_theme\": \"respiratory\",\n",
    "        \"topic\": \"COVID-19\", \"metric\": \"COVID-19_healthcare_occupiedBedsRollingMean\", \"geography_type\": \"NHS Region\"} #, \"geography\": \"England\"}\n",
    "    \n",
    "    \n",
    "    mean_occBed_region = []\n",
    "    for idx, r in enumerate(regions):\n",
    "        structure[\"geography\"] = r\n",
    "        api=APIwrapper(**structure)\n",
    "        mean_occBed_region.append(api.get_all_pages(filters))                    \n",
    "        print(f\"Data points expected: {api.count}\")\n",
    "        print(f\"Data points retrieved: {len(mean_occBed_region[idx])}\")\n",
    "        \n",
    "    with open(\"mean_occBed_region.json\", \"wt\") as OUTF:\n",
    "        json.dump(mean_occBed_region, OUTF)\n",
    "        \n",
    "\n",
    "    return mean_occBed_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "Data points expected: 1547\n",
      "Data points retrieved: 1547\n",
      "2020-08-07 00:00:00  to  2024-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "    apidata=access_api()\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "    global df1, df2\n",
    "    global regions \n",
    "    regions = [\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"]\n",
    "    df1=wrangle_data(apidata)\n",
    "    # the graph won't refresh until the user interacts with the widget.\n",
    "    # this function simulates the interaction, see Graph and Analysis below.\n",
    "    # The function needs to be adapted to your graph; you can omit this call\n",
    "    # in the first instance\n",
    "    refresh_graph()\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. If you are \n",
    "    # implementing error handling, you can use icons \"unlink\" or \"times\" and \n",
    "    # change the button text to \"Unavailable\" when the api call fails.\n",
    "    apibutton.icon=\"check\"\n",
    "    # apibutton.disabled=True\n",
    "\n",
    "    \n",
    "apibutton=wdg.Button(\n",
    "    description='Engage', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Make it so\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='exclamation-triangle'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "# display(apibutton)\n",
    "\n",
    "# run all cells before clicking on this button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include at least one graph with interactive controls, as well as some instructions for the user and/or comments on what the graph represents and how it should be explored (this example shows two random walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8062e3353b724dccaa6408b147cae6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='danger', description='Engage', icon='exclamation-triangle', style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aff51bfc3b743298405864ec8acb408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_plot(selected_regions, date_range):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    selected_regions = list(selected_regions)                   # make a list of the regions to filter by\n",
    "    start_date, end_date = date_range                           # pull the start and end date out of the tuple              \n",
    "    df1a = df1.loc[start_date:end_date, selected_regions].copy()               \n",
    "    df1a.plot(ax=ax)\n",
    "    ax.set_title(\"Mean Beds Occupied by Region\")\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "    ax.tick_params(axis='x', which='minor', rotation=65)\n",
    "    ax.tick_params(axis='x', which='major', rotation=65)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "\n",
    "    # since df is a reasonable size decided to filter data rather than the plot\n",
    "    # ax.set_xlim([start_date, end_date])   \n",
    "                        \n",
    "    # since filtering date by the data, can scale the y-axis based on the date range\n",
    "    ax.set_ylim([df1a.min().min(), df1a.max().max()+50])\n",
    "    \n",
    "    plt.show()\n",
    "  \n",
    "\n",
    "reg = wdg.SelectMultiple(\n",
    "    options=[\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"],\n",
    "    value=[\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"],\n",
    "    description='Regions',\n",
    "    disabled=False\n",
    ")\n",
    "reg.layout.height = '120px'\n",
    "\n",
    "dates = pd.date_range(start='2020-08-01', end='2024-10-31', freq='MS')\n",
    "options = [(i.strftime('%b %Y'), i) for i in dates]\n",
    "dates_slider = wdg.SelectionRangeSlider(\n",
    "    options=options,\n",
    "    index=(0, 50),\n",
    "    description='Period',\n",
    "    disabled=False,\n",
    "    layout=wdg.Layout(width='40%')\n",
    ")\n",
    "\n",
    "# forcably prevent the start date equalling the end date. Not very elegant.\n",
    "def validate_date_range(change):\n",
    "    start, end = change['new']\n",
    "    if start.year == end.year and start.month == end.month:\n",
    "        if start == dates[0]:\n",
    "            end = dates[1]\n",
    "        else:\n",
    "            start = dates[dates.get_loc(end) - 1]\n",
    "        yr.value = (start, end)\n",
    "\n",
    "dates_slider.observe(validate_date_range, names='value')\n",
    "\n",
    "\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "    current=reg.value\n",
    "    #print(current)\n",
    "    if current==reg.options[0]:\n",
    "        other=reg.options[1]\n",
    "        #print(\"was reg.options[0]\",other)\n",
    "    else:\n",
    "        other=reg.options[0]\n",
    "        #print(\"was reg.options[1]\",other)\n",
    "    reg.value=(other,) # forces the redraw\n",
    "    reg.value=current # now we can change it back\n",
    "    \n",
    "controls0=wdg.HBox([apibutton, reg, dates_slider]) \n",
    "\n",
    "# connect the plotting function and the widget    \n",
    "graph0=wdg.interactive_output(update_plot, {'selected_regions': reg, 'date_range': dates_slider})\n",
    "\n",
    "# actually displays the graph\n",
    "display(controls0, graph0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Option Titles\n",
    "\n",
    "I'd heard of tree datastuctures a few years ago and decided to map the whole api to a tree structure. this took nearly an hour on my machine so it is written to a pickle file and loaded from there. The mapping code is included in the function `add_branch_to_node`. Each node has a dictinoary containing the api link and the name, and the function explores all branches down to the metrics data. The code checks when a dropdown is changed and updates the following dropdowns so you can't have parent showing that doesn't belong to a child that is shown in another dropdown.  \n",
    "I wanted to try pulling the data from the link in the Metrics dictionary, rather than building a link with the structure, so retrieved the pages outside the APIwrapper class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02551bf3ab9f44678b999afca844ecb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='1. Theme:', layout=Layout(width='30%'), options=(('infecti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a5d191b7ce4433afa423d9a55202f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the pickle of the tree (if not loaded from file takes nearly an hour to generate)\n",
    "with open('full_tree_named.pkl', 'rb') as f:\n",
    "    root = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "def getMetric_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "    leaf_data = requests.get(metric_link, params={ 'page_size': 1800, 'page': 1}).json()\n",
    "    \n",
    "    # One-off to save json data to file\n",
    "    # with open(\"leaf_first.json\", \"wt\") as OUTF:\n",
    "    #     json.dump(leaf_data, OUTF)\n",
    "    \n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "    global df2\n",
    "    df2=wrangle_leaf_data(leaf_data)\n",
    "    \n",
    "    refresh_graph()\n",
    "\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. If you are \n",
    "    # implementing error handling, you can use icons \"unlink\" or \"times\" and \n",
    "    # change the button text to \"Unavailable\" when the api call fails.\n",
    "    getMetric_button.icon=\"check\"\n",
    "    # apibutton.disabled=True\n",
    "\n",
    "    \n",
    "getMetric_button=wdg.Button(\n",
    "    description='Engage', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Make it so\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='exclamation-triangle'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "getMetric_button.on_click(getMetric_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wrangle_leaf_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    \n",
    "    def parse_date(datestring):\n",
    "        \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "        return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "    data={}\n",
    "    for entry in rawdata['results']:\n",
    "        date=entry['date']\n",
    "        value=entry['metric_value']\n",
    "        if date not in data:\n",
    "            data[date] = value\n",
    "\n",
    "    dates=list(data.keys())\n",
    "    dates.sort()\n",
    "\n",
    "    startdate=parse_date(dates[0])\n",
    "    enddate=parse_date(dates[-1])\n",
    "\n",
    "    index=pd.date_range(startdate, enddate, freq='D')\n",
    "    leaf_metric_df = pd.DataFrame(index=index, columns=['Metric'])\n",
    "\n",
    "    for date, value in data.items(): # each entry is a dictionary with cases, admissions and deaths\n",
    "        pd_date=parse_date(date) # convert to Pandas format\n",
    "        # do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "        # this is the way you access a specific location in the dataframe - use .loc\n",
    "        # and put index,column in a single set of [ ]\n",
    "        leaf_metric_df.loc[date, 'Metric'] = value\n",
    "    leaf_metric_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    return leaf_metric_df\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric(change, title):                                        # revieves a change parameter from the widget to refresh, but not used\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))             \n",
    "    df2.plot(ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "    ax.tick_params(axis='x', which='minor', rotation=80)\n",
    "    ax.tick_params(axis='x', which='major', rotation=80)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# helper dropdown to change without impact, and update graph. Not displayed in control1\n",
    "helper=wdg.Dropdown(\n",
    "    options=['One', 'Two'],\n",
    "    value='One',\n",
    "    description='helper',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\"Change the value of the widget in order to force a redraw of the graph\n",
    "    since we pull from the API every time with this graph.\n",
    "    Don't want the useful dropdowns to change as they can trigger a reset and also\n",
    "    not all dropdowns have >1 choice.\"\"\"\n",
    "    current=helper.value\n",
    "    if current==helper.options[0]:\n",
    "        other=helper.options[1]\n",
    "    else:\n",
    "        other=helper.options[0]\n",
    "    helper.value=other # forces the redraw\n",
    "    helper.value=current # now we can change it back\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# function to create a dropdown widgets, rather than one by one\n",
    "def create_dropdown(description, options):\n",
    "    return wdg.Dropdown(\n",
    "        options=options,\n",
    "        value=options[0][1] if options else None,\n",
    "        description=description,\n",
    "        disabled=False,\n",
    "        style={'description_width': '90px'},\n",
    "        layout=wdg.Layout(width='30%')\n",
    "    )\n",
    "\n",
    "\n",
    "# problem with changing earlier dropdowns messing up later dropdown values, e.g. changing sub theme after topics were chosen\n",
    "# so need to update them all\n",
    "def update_options(dropdown, options):\n",
    "    dropdown.options = options\n",
    "    if options:\n",
    "        dropdown.value = options[0][1]\n",
    "    else:\n",
    "        dropdown.value = None\n",
    "\n",
    "# update each dropdown\n",
    "def update_subthemes(*args):\n",
    "    if theme_dd.value is not None:  # it has a value that might not work with a previous selection (not a problem for theme at the moment but future proofing)\n",
    "        update_options(subTheme_dd, [(child.name, idx) for idx, child in enumerate(root.children[theme_dd.value].children)])\n",
    "        update_topics()\n",
    "\n",
    "def update_topics(*args):\n",
    "    if subTheme_dd.value is not None:\n",
    "        update_options(topic_dd, [(child.name, idx) for idx, child in enumerate(root.children[theme_dd.value].children[subTheme_dd.value].children)])\n",
    "        update_geotypes()\n",
    "\n",
    "def update_geotypes(*args):\n",
    "    if topic_dd.value is not None:\n",
    "        update_options(geoType_dd, [(child.name, idx) for idx, child in enumerate(root.children[theme_dd.value].children[subTheme_dd.value].children[topic_dd.value].children)])\n",
    "        update_geographies()\n",
    "\n",
    "def update_geographies(*args):\n",
    "    if geoType_dd.value is not None:\n",
    "        update_options(geographies_dd, [(child.name, idx) for idx, child in enumerate(root.children[theme_dd.value].children[subTheme_dd.value].children[topic_dd.value].children[geoType_dd.value].children)])\n",
    "        update_metrics()\n",
    "\n",
    "def update_metrics(*args):\n",
    "    if geographies_dd.value is not None:\n",
    "        update_options(metrics_dd, [(child.name, idx) for idx, child in enumerate(root.children[theme_dd.value].children[subTheme_dd.value].children[topic_dd.value].children[geoType_dd.value].children[geographies_dd.value].children)])\n",
    "\n",
    "# create the dropdown widgets\n",
    "theme_dd = create_dropdown('1. Theme:', [(child.name, idx) for idx, child in enumerate(root.children)])\n",
    "subTheme_dd = create_dropdown('2. Sub Theme:', [])\n",
    "topic_dd = create_dropdown('3. Topic:', [])\n",
    "geoType_dd = create_dropdown('4. Geo Type:', [])\n",
    "geographies_dd = create_dropdown('5. Geographies:', [])\n",
    "metrics_dd = create_dropdown('6. Metrics:', [])\n",
    "\n",
    "\n",
    "\n",
    "def update_metric_link(*args):\n",
    "    global metric_link\n",
    "    metric_link = root.children[theme_dd.value].children[subTheme_dd.value].children[topic_dd.value].children[geoType_dd.value].children[geographies_dd.value].children[metrics_dd.value].link\n",
    "\n",
    "\n",
    "# observe the dropdowns so downstream resets when a value changes\n",
    "theme_dd.observe(update_subthemes, names='value')\n",
    "subTheme_dd.observe(update_topics, names='value')\n",
    "topic_dd.observe(update_geotypes, names='value')\n",
    "geoType_dd.observe(update_geographies, names='value')\n",
    "geographies_dd.observe(update_metrics, names='value')\n",
    "\n",
    "# Observe all dropdowns to update the metric link\n",
    "theme_dd.observe(update_metric_link, names='value')\n",
    "subTheme_dd.observe(update_metric_link, names='value')\n",
    "topic_dd.observe(update_metric_link, names='value')\n",
    "geoType_dd.observe(update_metric_link, names='value')\n",
    "geographies_dd.observe(update_metric_link, names='value')\n",
    "metrics_dd.observe(update_metric_link, names='value')\n",
    "\n",
    "update_subthemes(None)\n",
    "\n",
    "controls1 = wdg.VBox([\n",
    "    wdg.HBox([theme_dd, subTheme_dd, topic_dd], layout=wdg.Layout(justify_content='space-between', width='100%')),\n",
    "    wdg.HBox([geoType_dd, geographies_dd, metrics_dd], layout=wdg.Layout(justify_content='space-between', width='100%')), \n",
    "    getMetric_button\n",
    "])\n",
    "\n",
    "# plot first graph from file data\n",
    "df2=wrangle_leaf_data(leaf_data) # df is the dataframe for plotting\n",
    "\n",
    "# connect the plotting function and the widget    \n",
    "graph1=wdg.interactive_output(plot_metric, {'change' : helper, 'title': wdg.fixed(metrics_dd.label)})   # get the label to send to the plotting function as a title\n",
    "\n",
    "# actually displays the graph\n",
    "display(controls1, graph1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wrangle_leaf_data(rawdata):\n",
    "#     \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "#     Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    \n",
    "#     def parse_date(datestring):\n",
    "#         \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "#         return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "#     data={}\n",
    "#     for entry in rawdata['results']:\n",
    "#         date=entry['date']\n",
    "#         value=entry['metric_value']\n",
    "#         if date not in data:\n",
    "#             data[date] = value\n",
    "\n",
    "#     dates=list(data.keys())\n",
    "#     dates.sort()\n",
    "\n",
    "#     startdate=parse_date(dates[0])\n",
    "#     enddate=parse_date(dates[-1])\n",
    "\n",
    "#     index=pd.date_range(startdate, enddate, freq='D')\n",
    "#     leaf_metric_df = pd.DataFrame(index=index, columns=['Metric'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for date, value in data.items(): # each entry is a dictionary with cases, admissions and deaths\n",
    "#         pd_date=parse_date(date) # convert to Pandas format\n",
    "#         # do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "#         # this is the way you access a specific location in the dataframe - use .loc\n",
    "#         # and put index,column in a single set of [ ]\n",
    "#         leaf_metric_df.loc[date, 'Metric'] = value\n",
    "#     leaf_metric_df.fillna(0.0, inplace=True)\n",
    "\n",
    "#     return leaf_metric_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# df2=wrangle_leaf_data(leaf_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the dashboard\n",
    "\n",
    "Once your code is ready and you are satisfied with the appearance of the graphs, replace all the text boxes above with the explanations you would like a dashboard user to see. The next step is deploying the dashboard online - there are several [options](https://voila.readthedocs.io/en/stable/deploy.html) for this, we suggest deploying as a [Binder](https://mybinder.org/). This is basically the same technique that has been used to package this tutorial and to deploy this template dashboard. The instructions may seem a bit involved, but the actual steps are surprisingly easy - we will be going through them together during a live session. You will need an account on [GitHub](https://github.com/) for this - if you don't have one already, now it's the time to create it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author and License** Remember that if you deploy your dashboard as a Binder it will be publicly accessible. Change the copyright notice and take credit for your work! Also acknowledge your sources and the conditions of the license by including this notice: \"Based on UK Government [data](https://ukhsa-dashboard.data.gov.uk/) published by the [UK Health Security Agency](https://www.gov.uk/government/organisations/uk-health-security-agency) and on the [DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) by Fabrizio Smeraldi. Released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
