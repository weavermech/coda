{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020,2024 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Disease Tracking Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template for your DIY Disease Tracking Dashboard, to which you can add the code you developed in the previous notebooks. The dashboard will be displayed using [voila](https://voila.readthedocs.io/en/stable/index.html), a Python dashboarding tool that converts notebooks to standalone dashboards. Contrary to the other libraries we have seen, the ```voila``` package must be installed using *pip* or *conda* but it does not need to be imported - it rather acts at the level of the notebook server. Package ```voila``` is already installed on the QMUL JupyterHub as well as in the Binder - to install it locally, follow the [instructions](https://voila.readthedocs.io/en/stable/install.html) online.\n",
    "\n",
    "Broadly speaking, Voila acts by **running all the cells in your notebook** when the dashboard is first loaded; it then hides all code cells and displays all markdown cells and any outputs, including widgets. However, the code is still there in the background and handles any interaction with the widgets. To view this dashboard template rendered in Voila click [here](https://mybinder.org/v2/gh/fsmeraldi/diy-covid19dash/main?urlpath=%2Fvoila%2Frender%2FDashboard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "from anytree.importer import JsonImporter, DictImporter\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "global regions \n",
    "regions = [\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial data from disk\n",
    "\n",
    "You should include \"canned\" data in ```.json``` files along with your dashboard. When the dashboard starts, it should load that data and assign it as a dictionary to the ```jsondata``` variable (the code below will be hidden when the dashboard is rendered by Voila)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "with open(\"mean_occBed_region.json\", \"rt\") as INFILE:\n",
    "    mean_occBed_region=json.load(INFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the data\n",
    "\n",
    "The dashboard should contain the logic to wrangle the raw data into a ```DataFrame``` (or more than one, as required) that will be used for plotting. The wrangling code should be put into a function and called on the data from the JSON file (we'll need to call it again on any data downloaded from the API).  In this template, we just pretend we are wrangling ```rawdata``` and instead generate a dataframe with some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01 00:00:00  to  2022-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def wrangle_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    \n",
    "    def parse_date(datestring):\n",
    "        \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "        return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "    data={}\n",
    "    for dataset in rawdata:\n",
    "        for entry in dataset:\n",
    "            date=entry['date']\n",
    "            value=entry['metric_value']\n",
    "            geography=entry['geography']\n",
    "            if date not in data:\n",
    "                data[date]={}\n",
    "            data[date][geography]=value\n",
    "\n",
    "    dates=list(data.keys())\n",
    "    dates.sort()\n",
    "\n",
    "    startdate=parse_date(dates[0])\n",
    "    enddate=parse_date(dates[-1])\n",
    "    print (startdate, ' to ', enddate)\n",
    "\n",
    "    index=pd.date_range(startdate, enddate, freq='D')\n",
    "    mean_occBed_region_df=pd.DataFrame(index=index, columns=regions)\n",
    "\n",
    "\n",
    "    for date, values in data.items():\n",
    "        for region, value in values.items():\n",
    "            mean_occBed_region_df.at[parse_date(date), region] = value\n",
    "    # fill in any remaining \"holes\" due to missing dates\n",
    "    mean_occBed_region_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    return mean_occBed_region_df\n",
    "\n",
    "    \n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n",
    "df1=wrangle_data(mean_occBed_region) # df is the dataframe for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your users an option to refresh the dataset - a \"refresh\" button will do. The button callback should\n",
    "* call the code that accesses the API and download some fresh raw data;\n",
    "* wrangle that data into a dataframe and update the corresponding (global) variable for plotting (here, ```df```);\n",
    "* optionally: force a redraw of the graph and give the user some fredback.\n",
    "\n",
    "Once you get it to work, you may want to wrap your API call inside an exception handler, so that the user is informed, the \"canned\" data are not overwritten and nothing crashes if for any reason the server cannot be reached or data are not available.\n",
    "\n",
    "After you refresh the data, graphs will not update until the user interacts with a widget. You can trick ```iPywidgets``` into redrawing the graph by simulating interaction, as in the ```refresh_graph``` function we define in the Graph and Analysis section below.\n",
    "\n",
    "In this example, clicking on the button below just generates some more random data and refreshes the graph. The button should read *Fetch Data*. If you see anything else, take a deep breath :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the UKHSA API. Return data as a like-for-like replacement for the \"canned\" data loaded from the JSON file. \"\"\"\n",
    "    \n",
    "    class APIwrapper:\n",
    "        # class variables shared among all instances\n",
    "        _access_point=\"https://api.ukhsa-dashboard.data.gov.uk/v2\"         # v2??????????????????????????????????????????\n",
    "        _last_access=0.0 # time of last api access\n",
    "        root = Node(\"root\")\n",
    "        \n",
    "        def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "            \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "            parameters \"\"\"\n",
    "            # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "            # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "            url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                    f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "            # our starting API endpoint\n",
    "            self._start_url=APIwrapper._access_point+url_path\n",
    "            self._filters=None\n",
    "            self._page_size=-1\n",
    "            # will contain the number of items\n",
    "            self.count=None\n",
    "\n",
    "\n",
    "\n",
    "        def get_page(self, filters={}, page_size=5):\n",
    "            \"\"\" Access the API and download the next page of data. Sets the count\n",
    "            attribute to the total number of items available for this query. Changing\n",
    "            filters or page_size will cause get_page to restart from page 1. Rate\n",
    "            limited to three request per second. The page_size parameter sets the number\n",
    "            of data points in one response page (maximum 365); use the default value \n",
    "            for debugging your structure and filters. \"\"\"\n",
    "            # Check page size is within range\n",
    "            if page_size>365:\n",
    "                raise ValueError(\"Max supported page size is 365\")\n",
    "            # restart from first page if page or filters have changed\n",
    "            if filters!=self._filters or page_size!=self._page_size:\n",
    "                self._filters=filters\n",
    "                self._page_size=page_size\n",
    "                self._next_url=self._start_url\n",
    "            # signal the end of data condition\n",
    "            if self._next_url==None: \n",
    "                return [] # we already fetched the last page\n",
    "            # simple rate limiting to avoid bans\n",
    "            curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "            deltat=curr_time-APIwrapper._last_access\n",
    "            if deltat<0.33: # max 3 requests/second\n",
    "                time.sleep(0.33-deltat)\n",
    "            APIwrapper._last_access=curr_time\n",
    "            # build parameter dictionary by removing all the None\n",
    "            # values from filters and adding page_size\n",
    "            parameters={x: y for x, y in filters.items() if y!=None}\n",
    "            parameters['page_size']=page_size\n",
    "            # the page parameter is already included in _next_url.\n",
    "            # This is the API access. Response is a dictionary with various keys.\n",
    "            # the .json() method decodes the response into Python object (dictionaries,\n",
    "            # lists; 'null' values are translated as None).\n",
    "            response = requests.get(self._next_url, params=parameters).json()\n",
    "            # update url so we'll fetch the next page\n",
    "            self._next_url=response['next']\n",
    "            self.count=response['count']\n",
    "            # data are in the nested 'results' list\n",
    "            return response['results'] \n",
    "\n",
    "        def get_all_pages(self, filters={}, page_size=365):\n",
    "            \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "            attribute to the total number of items available for this query. API access rate\n",
    "            limited to three request per second. The page_size parameter sets the number\n",
    "            of data points in one response page (maximum 365), and controls the trade-off\n",
    "            between time to load a page and number of pages; the default should work well \n",
    "            in most cases. The number of items returned should in any case be equal to \n",
    "            the count attribute. \"\"\"\n",
    "            data=[] # build up all data here\n",
    "            while True:\n",
    "                # use get_page to do the job, including the pacing\n",
    "                next_page=self.get_page(filters, page_size)\n",
    "                if next_page==[]:\n",
    "                    break # we are done\n",
    "                data.extend(next_page)\n",
    "            return data\n",
    "\n",
    "\n",
    "        # /themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/{geography_type}/geographies/{geography}/metrics/{metric}\n",
    "        #REDO so starts from _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\" \n",
    "        def add_branch_to_node(self, upper_node = root, link = _access_point+'/themes/'):\n",
    "            importer = DictImporter()\n",
    "            curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "            deltat=curr_time-APIwrapper._last_access\n",
    "            if deltat<0.33: # max 3 requests/second\n",
    "                time.sleep(0.33-deltat)\n",
    "            APIwrapper._last_access=curr_time\n",
    "\n",
    "            branches = requests.get(link).json()\n",
    "            \n",
    "            # \n",
    "            if branches:        # make this better api stuff, 200?\n",
    "                for branch in branches:\n",
    "                    new_node = importer.import_(branch)\n",
    "                    new_node.parent = upper_node\n",
    "                    new_node.name = branch['name']\n",
    "                    #print(RenderTree(root))\n",
    "                    curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "                    deltat=curr_time-APIwrapper._last_access\n",
    "                    if deltat<0.33: # max 3 requests/second\n",
    "                        time.sleep(0.33-deltat)\n",
    "                    APIwrapper._last_access=curr_time  \n",
    "                    \n",
    "                    next_level_link = branch['link']  # get the link to the next section in the api\n",
    "                    options_link = requests.get(next_level_link).json()\n",
    "                    if list(options_link[0].keys())[0] == 'metrics':        # bottom of tree\n",
    "                        continue                                            # move on to next branch\n",
    "                    options_link = list(options_link[0].values())[0]\n",
    "                    \n",
    "                    self.add_branch_to_node(new_node, options_link)\n",
    "\n",
    "            return\n",
    "    \n",
    "    # This Builds The Tree !!It Takes Over 30 min To Run on Local Machine!!\n",
    "    # api.add_branch_to_node()\n",
    "    \n",
    "    # Load the tree from a pickle file instead\n",
    "    global root\n",
    "    with open('full_tree.pkl', 'rb') as f:\n",
    "        root = pickle.load(f)\n",
    "\n",
    "    filters={\"stratum\" : None, # Smallest subgroup a metric can be broken down into e.g. ethnicity, testing pillar\n",
    "        \"age\": None, # Smallest subgroup a metric can be broken down into e.g. 15_44 for the age group of 15-44 years\n",
    "        \"sex\": None, #  Patient gender e.g. 'm' for Male, 'f' for Female or 'all' for all genders\n",
    "        \"year\": 2022, #  Epi year of the metrics value (important for annual metrics) e.g. 2020\n",
    "        \"month\": None, # Epi month of the metric value (important for monthly metrics) e.g. 12\n",
    "        \"epiweek\" :None, # Epi week of the metric value (important for weekly metrics) e.g. 30\n",
    "        \"date\" : None, # The date which this metric value was recorded in the format YYYY-MM-DD e.g. 2020-07-20\n",
    "        \"in_reporting_delay_period\": None # Boolean indicating whether the data point is considered to be subject to retrospective updates\n",
    "    }\n",
    "    \n",
    "    structure={\"theme\": \"infectious_disease\", \n",
    "        \"sub_theme\": \"respiratory\",\n",
    "        \"topic\": \"COVID-19\", \"metric\": \"COVID-19_healthcare_occupiedBedsRollingMean\", \"geography_type\": \"NHS Region\"} #, \"geography\": \"England\"}\n",
    "    \n",
    "    \n",
    "    mean_occBed_region = []\n",
    "    for idx, r in enumerate(regions):\n",
    "        structure[\"geography\"] = r\n",
    "        api=APIwrapper(**structure)\n",
    "        mean_occBed_region.append(api.get_all_pages(filters))                    # FILTERED!!!! 2022 only\n",
    "        print(f\"Data points expected: {api.count}\")\n",
    "        print(f\"Data points retrieved: {len(mean_occBed_region[idx])}\")\n",
    "        \n",
    "        \n",
    "    #timeseriesdf = wrangle_data(mean_occBed_region)   \n",
    "\n",
    "\n",
    "    \n",
    "    #return timeseriesdf # return data read from the API\n",
    "    return mean_occBed_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11e49466a34a9a8f40ee5523c1c801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Engage', icon='exclamation-triangle', style=ButtonStyle(), tooltip=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'full_tree.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mapi_button_callback\u001b[0;34m(button)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Button callback - it must take the button as its parameter (unused in this case).\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mAccesses API, wrangles data, updates global variable df used for plotting. \"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get fresh data from the API. If you have time, include some error handling\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# around this call.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m apidata\u001b[38;5;241m=\u001b[39m\u001b[43maccess_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# wrangle the data and overwrite the dataframe for plotting\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m df1\n",
      "Cell \u001b[0;32mIn[5], line 125\u001b[0m, in \u001b[0;36maccess_api\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# This Builds The Tree !!It Takes Over 30 min To Run on Local Machine!!\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# api.add_branch_to_node()\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Load the tree from a pickle file instead\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m root\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_tree.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    126\u001b[0m     root \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    128\u001b[0m filters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstratum\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Smallest subgroup a metric can be broken down into e.g. ethnicity, testing pillar\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Smallest subgroup a metric can be broken down into e.g. 15_44 for the age group of 15-44 years\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#  Patient gender e.g. 'm' for Male, 'f' for Female or 'all' for all genders\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_reporting_delay_period\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Boolean indicating whether the data point is considered to be subject to retrospective updates\u001b[39;00m\n\u001b[1;32m    136\u001b[0m }\n",
      "File \u001b[0;32m~/uni/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'full_tree.pkl'"
     ]
    }
   ],
   "source": [
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "    apidata=access_api()\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "    global df1\n",
    "    global regions \n",
    "    regions = [\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"]\n",
    "    df=wrangle_data(apidata)\n",
    "    # the graph won't refresh until the user interacts with the widget.\n",
    "    # this function simulates the interaction, see Graph and Analysis below.\n",
    "    # The function needs to be adapted to your graph; you can omit this call\n",
    "    # in the first instance\n",
    "    refresh_graph()\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. If you are \n",
    "    # implementing error handling, you can use icons \"unlink\" or \"times\" and \n",
    "    # change the button text to \"Unavailable\" when the api call fails.\n",
    "    apibutton.icon=\"check\"\n",
    "    # apibutton.disabled=True\n",
    "\n",
    "    \n",
    "apibutton=wdg.Button(\n",
    "    description='Engage', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Keep calm and carry on\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='exclamation-triangle'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "display(apibutton)\n",
    "\n",
    "# run all cells before clicking on this button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include at least one graph with interactive controls, as well as some instructions for the user and/or comments on what the graph represents and how it should be explored (this example shows two random walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e808d329fd01462da605f977afb9e2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='danger', description='Engage', icon='exclamation-triangle', style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5079259c11dd4829935ae5afc52ed1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_plot(selected_regions):\n",
    "    #selected_regions = [region for region, checkbox in region_checkboxes.items() if checkbox.value]\n",
    "    selected_regions = list(selected_regions)\n",
    "    df1[selected_regions].plot()\n",
    "    # ax = df1[selected_regions].plot()\n",
    "    # ax.set_title(\"test title\")\n",
    "    # ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    # ax.xaxis.set_minor_formatter(mdates.DateFormatter('%b'))\n",
    "    # ax.tick_params(axis='x', which='minor', rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "reg = wdg.SelectMultiple(\n",
    "    options=[\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"],\n",
    "    value=[\"North East and Yorkshire\", \"North West\", \"Midlands\", \"South West\", \"East of England\", \"London\", \"South East\"],\n",
    "    #rows=10,\n",
    "    description='Regions',\n",
    "    disabled=False\n",
    ")\n",
    "reg.layout.height = '120px'\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "    current=reg.value\n",
    "    if current==reg.options[0]:\n",
    "        other=reg.options[1]\n",
    "    else:\n",
    "        other=reg.options[0]\n",
    "    reg.value=other # forces the redraw\n",
    "    reg.value=current # now we can change it back\n",
    "    \n",
    "controls=wdg.HBox([apibutton, reg]) \n",
    "\n",
    "# connect the plotting function and the widget    \n",
    "graph=wdg.interactive_output(update_plot, {'selected_regions': reg})\n",
    "\n",
    "# actually displays the graph\n",
    "display(controls, graph)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def refresh_graph():\n",
    "#     \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "#     this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "#     needs to be customised for one of your widgets. \"\"\"\n",
    "    \n",
    "#     # current=region_checkboxes[list(region_checkboxes.keys())[0]].value\n",
    "#     # if current==region_checkboxes[list(region_checkboxes.keys())[0]].options[0]:\n",
    "#     #     other=region_checkboxes[list(region_checkboxes.keys())[0]].options[1]\n",
    "#     # else:\n",
    "#     #     other=region_checkboxes[list(region_checkboxes.keys())[0]].options[0]\n",
    "#     # region_checkboxes[list(region_checkboxes.keys())[0]].value=other # forces the redraw\n",
    "#     # region_checkboxes[list(region_checkboxes.keys())[0]].value=current # now we can change it back\n",
    "#       change to not checkbox?\n",
    "#     current=region_checkboxes[list(region_checkboxes.keys())[0]].value\n",
    "#     region_checkboxes[list(region_checkboxes.keys())[0]].value = not current\n",
    "#     region_checkboxes[list(region_checkboxes.keys())[0]].value = current\n",
    "    \n",
    "\n",
    "# region_checkboxes = {region: wdg.Checkbox(value=True, description=region) for region in regions}\n",
    "# for checkbox in region_checkboxes.values():\n",
    "#     checkbox.observe(update_plot, 'value')\n",
    "\n",
    "# # Create two horizontal rows of checkboxes\n",
    "# row1 = wdg.HBox(list(region_checkboxes.values())[:4])\n",
    "# row2 = wdg.HBox(list(region_checkboxes.values())[4:])\n",
    "\n",
    "# # try replacing HBox with a VBox!!\n",
    "# controls=wdg.HBox([apibutton, wdg.VBox([row1, row2])])\n",
    "\n",
    "# # capture output in widget graph   \n",
    "# graph=wdg.interactive_output(update_plot, {'change': region_checkboxes[regions[0]]})\n",
    "\n",
    "# display(controls, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the dashboard\n",
    "\n",
    "Once your code is ready and you are satisfied with the appearance of the graphs, replace all the text boxes above with the explanations you would like a dashboard user to see. The next step is deploying the dashboard online - there are several [options](https://voila.readthedocs.io/en/stable/deploy.html) for this, we suggest deploying as a [Binder](https://mybinder.org/). This is basically the same technique that has been used to package this tutorial and to deploy this template dashboard. The instructions may seem a bit involved, but the actual steps are surprisingly easy - we will be going through them together during a live session. You will need an account on [GitHub](https://github.com/) for this - if you don't have one already, now it's the time to create it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author and License** Remember that if you deploy your dashboard as a Binder it will be publicly accessible. Change the copyright notice and take credit for your work! Also acknowledge your sources and the conditions of the license by including this notice: \"Based on UK Government [data](https://ukhsa-dashboard.data.gov.uk/) published by the [UK Health Security Agency](https://www.gov.uk/government/organisations/uk-health-security-agency) and on the [DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) by Fabrizio Smeraldi. Released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
